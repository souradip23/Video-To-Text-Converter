# ğŸ¬ Video to Text Converter â€” Powered by Whisper AI

Convert your **video or audio files into text** using **OpenAI Whisper**, **Node.js**, **React**, and **FFmpeg**.  
This full-stack application demonstrates how to build a **real-world AI-powered transcription system** with a **modern, responsive UI** and **fast backend processing**.

---

## ğŸš€ Key Features

âœ… Upload any audio or video file  
âœ… Automatic speech-to-text conversion using **Whisper AI**  
âœ… **FFmpeg integration** for multi-format compatibility  
âœ… Real-time transcription feedback with progress status  
âœ… Download results as a `.txt` file  
âœ… Clean, modern **React + Tailwind CSS** UI  
âœ… Full **Node.js + Express.js** backend using **Multer** for file handling  
âœ… Supports formats: `.mp3`, `.wav`, `.mp4`, `.mkv`, `.mov`

---

# ğŸ§  Tech Stack

| Layer | Technologies Used |
|-------|-------------------|
| **Frontend** | React.js, Tailwind CSS |
| **Backend** | Node.js, Express.js, Multer |
| **AI Engine** | OpenAI Whisper (Python) |
| **Media Processing** | FFmpeg |
| **Languages** | JavaScript, Python |

---

## âš™ï¸ Setup Instructions

---

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/yourusername/video-to-text-converter.git
cd video-to-text-converter
```
---

### 2ï¸âƒ£ Backend Setup


Move into the backend folder:
```bash
cd backend
npm install
```
---
Create a .env file:
```bash
PORT=4000
```
---
Run the backend server:
```bash
node index.js
```
---
âœ… Server will start at http://localhost:4000
---
### 3ï¸âƒ£ Install Python & Whisper AI
---
Ensure Python 3.8+ is installed, then install Whisper globally:
```
pip install openai-whisper
```

### 4ï¸âƒ£ Install FFmpeg
---
Download FFmpeg from the Official FFmpeg Builds
.
Extract and add the bin folder path to your systemâ€™s Environment Variables.

Verify installation:
```
ffmpeg --version
```
### 5ï¸âƒ£ Frontend Setup
---
In another terminal:
```
cd frontend
npm install
npm run dev
```

Open your browser at:
ğŸ‘‰ http://localhost:5173
---


# ğŸ§© How It Works
---
ğŸ§ User uploads an audio/video file.

ğŸ“¨ File is sent to the backend using Multer.

ğŸ§° FFmpeg converts the file to .wav format (if needed).

ğŸ§  Whisper AI transcribes the speech into text.

ğŸ“¤ The backend sends the transcript back to the React frontend.

ğŸ“ User can view, copy, or download the generated transcript.

---
### ğŸª„ App Preview

 # Flow:
```
ğŸ¬ Upload â†’ âš™ï¸ Process â†’ ğŸ“œ View â†’ ğŸ’¾ Download
```
# Frontend UI Highlights:

âœ¨ Glassmorphism interface with dark mode

â³ Progress indicator during transcription

ğŸ“‹ Copy & ğŸ’¾ Download options for transcript

# ğŸ§‘â€ğŸ’» Learning Outcomes

File upload handling using Multer

Integrating OpenAI Whisper with Node.js

Converting & preprocessing media using FFmpeg

Building a responsive React + Tailwind CSS interface

Creating a complete AI-powered full-stack application

 # ğŸ“‚ Project Structure
 ```
Video-to-Text-Converter/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ index.js
â”‚   â”œâ”€â”€ audioService.js
â”‚   â”œâ”€â”€ uploads/
â”‚   â””â”€â”€ .env
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â””â”€â”€ UploadFile.jsx
â”‚   â”‚   â””â”€â”€ App.jsx
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ tailwind.config.js
â”‚
â””â”€â”€ README.md
```

# ğŸ§° Example Command (Manual Whisper Test)

You can test Whisper directly in the terminal:

whisper "E:/AI-Project/Text-Converter/backend/uploads/sample.wav" --model small --language en --output_format txt --output_dir "E:/AI-Project/Text-Converter/backend/uploads"

# â¤ï¸ Credits

Developed by Souradip
âœ¨ Powered by OpenAI Whisper, Node.js, and React
